{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans, DBSCAN\n",
    "from skopt import BayesSearchCV\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.concat([pd.read_csv(\"train.csv\"),\n",
    "               pd.read_csv(\"test.csv\")], ignore_index=True)\n",
    "df['is_male'] = df['gender'].map({'M': 1, 'F': 0}).astype(bool)\n",
    "df.drop([\"gender\"], axis=1, inplace=True)\n",
    "\n",
    "df[\"trans_hour\"] = df[\"trans_time\"].apply(lambda x: int(x.split(\":\")[0]))\n",
    "df.drop([\"trans_time\"], axis=1, inplace=True)\n",
    "\n",
    "df[\"trans_date\"] = pd.to_datetime(df['trans_date'], format='%Y-%m-%d')\n",
    "df[\"trans_day\"] = df[\"trans_date\"].dt.day\n",
    "df[\"trans_day\"] = df[\"trans_date\"].dt.day_of_week\n",
    "df['age'] = df['trans_date'].dt.year - \\\n",
    "    pd.to_datetime(df['dob'], format='%Y-%m-%d').dt.year\n",
    "df.drop([\"trans_date\", \"dob\"], axis=1, inplace=True)\n",
    "\n",
    "df['nth_trans_of_day'] = df.groupby(['cc_num', 'trans_day']).cumcount() + 1\n",
    "df['total_trans_of_day'] = df.groupby(['cc_num', 'trans_day'])['nth_trans_of_day'].transform('max')\n",
    "\n",
    "\n",
    "def haversine(lat1, lon1, lat2, lon2):\n",
    "    R = 6371\n",
    "    lat1, lon1, lat2, lon2 = map(np.radians, [lat1, lon1, lat2, lon2])\n",
    "    dlat = lat2 - lat1\n",
    "    dlon = lon2 - lon1\n",
    "    a = np.sin(dlat / 2) ** 2 + np.cos(lat1) * \\\n",
    "        np.cos(lat2) * np.sin(dlon / 2) ** 2\n",
    "    c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))\n",
    "    return R * c\n",
    "\n",
    "\n",
    "df['distance_to_merch'] = haversine(\n",
    "    df['lat'], df['long'], df['merch_lat'], df['merch_long'])\n",
    "df.drop(['merch_lat', 'merch_long', 'lat', 'long'], axis=1, inplace=True)\n",
    "\n",
    "category_encoder = OneHotEncoder(handle_unknown='ignore')\n",
    "encoded_columns = category_encoder.fit_transform(df[['category']])\n",
    "encoded_df = pd.DataFrame(encoded_columns.toarray(\n",
    "), columns=category_encoder.get_feature_names_out(['category']), index=df.index)\n",
    "encoded_df = encoded_df.astype(bool)\n",
    "df = df.join(encoded_df)\n",
    "df.drop(['category'], axis=1, inplace=True)\n",
    "\n",
    "\n",
    "for c in ['amt', 'city_pop', 'unix_time', 'distance_to_merch']:\n",
    "    scaler = StandardScaler()\n",
    "    df[c] = scaler.fit_transform(df[[c]])\n",
    "\n",
    "\n",
    "df.drop([\"trans_num\", \"first\", \"last\", \"merchant\", \"job\", \"street\", \"cc_num\",\n",
    "        \"city\", \"state\", \"zip\"], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tt = df[df['is_fraud'].notnull()]\n",
    "df_sub = df[df['is_fraud'].isnull()]\n",
    "\n",
    "X = df_tt.drop([\"is_fraud\"], axis=1)\n",
    "y = df_tt[\"is_fraud\"]\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_resampled, y_resampled = smote.fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_space = {\n",
    "    'n_estimators': (500,400),\n",
    "    'max_depth': (5, 40),\n",
    "    'learning_rate': (0.05, 0.5),\n",
    "    'subsample': (0.8, 1),\n",
    "    'colsample_bytree': (0.8, 1),\n",
    "}\n",
    "\n",
    "xgb = XGBClassifier(eval_metric='logloss', objective=\"binary:logistic\")\n",
    "\n",
    "opt = BayesSearchCV(\n",
    "    scoring='f1',\n",
    "    estimator=xgb,\n",
    "    search_spaces=param_space,\n",
    "    n_iter=256,\n",
    "    cv=5,\n",
    "    n_jobs=-1,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "opt.fit(X, y)\n",
    "\n",
    "print(\"Best parameters found: \", opt.best_params_)\n",
    "print(\"Best cross-validation score: \", opt.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt.best_estimator_.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_params = opt.best_params_\n",
    "xgb_best = XGBClassifier(\n",
    "    **best_params, eval_metric='logloss', objective=\"binary:logistic\")\n",
    "xgb_best.fit(X.drop(labels='id', axis=1), y)\n",
    "\n",
    "y_sub_pred = xgb_best.predict(df_sub.drop(labels=['is_fraud', 'id'], axis=1))\n",
    "\n",
    "submission = pd.DataFrame({\n",
    "    'id': df_sub['id'],\n",
    "    'is_fraud': y_sub_pred\n",
    "})\n",
    "\n",
    "\n",
    "submission.to_csv('submission.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tpot2env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
